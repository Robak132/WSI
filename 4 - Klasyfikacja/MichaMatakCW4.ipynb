{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michał Matak - Wprowadzenie do sztucznej inteligencji - ćwiczenie 4\n",
    "## Regresja i klasyfikacja "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Importowanie bibliotek\n",
    "* numpy - operacje na macierzach \n",
    "* scipy - optymalizacja parametryczna\n",
    "* matplotlib - tworzenie wykresów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje przekształcające strukturę zbioru danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobranie danych z pliku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = []\n",
    "    with open(\"iris.data\", \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            splitted_line = line.split(\",\")\n",
    "            if len(splitted_line) == 5:\n",
    "                data.append([list(map(float, splitted_line[:4])), encode(splitted_line[4][:-1])])\n",
    "        return data\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rezultatem jest lista **data** składająca się z list w formie: \\[ \\[atrybuty\\], \\[macierz odpowiadająca gatunkowi\\] \\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zakodowanie gatunku kosaćca w macierz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(name):\n",
    "    if name == 'Iris-setosa':\n",
    "        return [1, -1, -1]\n",
    "    elif name == 'Iris-versicolor':\n",
    "        return [-1, 1, -1]\n",
    "    elif name == 'Iris-virginica':\n",
    "        return [-1, -1, 1]\n",
    "    else:\n",
    "        raise Exception(\"Encoding error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział danych na zbiór testowy według **train_test_ratio**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_sets(train_test_ratio, data):\n",
    "    np.random.shuffle(data)\n",
    "    train_set_size = int(train_test_ratio*len(data))\n",
    "    test_set_size = len(data) - train_set_size\n",
    "    train_set = data[:train_set_size]\n",
    "    test_set = data[-test_set_size:]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział danych w zbiorze ze względu na klasy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    for row in data:\n",
    "        if row[1][0] == 1:\n",
    "            class1.append(row)\n",
    "        elif row[1][1] == 1:\n",
    "            class2.append(row)\n",
    "        elif row[1][2] == 1:\n",
    "            class3.append(row)\n",
    "        else:\n",
    "            raise Exception(\"https://tenor.com/view/thanos-impossible-marvel-shocked-gif-15104180\")\n",
    "    return class1, class2, class3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzenie zbioru danych w formie listy o elementach \\[atrybuty, przynależność (1 lub -1) do danej klasy podanej jako argument **index** \\].  \n",
    "Funkcja **make_2D_set** dodatkowo przymuje jako argument indeks kolumn, w których znajdują się wybrane atrybuty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_2D_set(feature1, feature2, index, data):\n",
    "    data_set = np.array([[row[0][feature1], row[0][feature2], row[1][index]] for row in data])\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def make_4D_set(index, data):\n",
    "    data_set = np.array([[row[0][0], row[0][1], row[0][2], row[0][3], row[1][index]] for row in data])\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje związane z SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja realizująca SVM **linear_SVM** przyjmuje jako argument zbiór z elementami postaci \\[atrybuty, przynależność (1 lub -1) do danej klasy\\] i zwraca **w** oraz **b** wyznaczające hiperpłaszczyznę dzielącą zbiór.  \n",
    "Zmiennymi globalnymi są **TRAIN_SET**, **RECORD_SIZE** oraz **LAMBDA**, oznaczające odpowiednio wielkość podanego zbioru, ilość atrybutów dla elementu w zbiorze oraz $\\lambda$. Zmienne te są globalne aby nie było potrzeby przekazywania ich jako parametry, do funkcji, która będzie minimalizowana (uznawała by je ona za zmienne i według nich szukała minimum).\n",
    "Funkcja minimize zaimportowana z biblioteki SciPy wykorzystuje poniżej zdefiniowane funkcje **constraint** oraz **target**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_SVM(train_set):\n",
    "    global TRAIN_SET\n",
    "    global RECORD_SIZE\n",
    "    global LAMBDA\n",
    "    LAMBDA = 0.5\n",
    "    TRAIN_SET = train_set\n",
    "    RECORD_SIZE = len(TRAIN_SET[0]) - 1\n",
    "    constraint = NonlinearConstraint(constraint1, np.zeros(len(TRAIN_SET)), np.inf)\n",
    "    res = minimize(target, np.random.random(RECORD_SIZE + 1), constraints=constraint)\n",
    "    w = res.x[:RECORD_SIZE]\n",
    "    b = res.x[RECORD_SIZE]\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja **target** jest równoważna:  \n",
    "\n",
    "<center>$\\sum_i\\zeta_i + \\lambda \\|w\\|$</center>\n",
    "  \n",
    "      \n",
    "    \n",
    "  \n",
    "która jest minimalizowana dla argumentów *w* i *b* przez **minimize**. Argumenty te są zebrane w jednej liście aby funkcja optymalizująca mogła działać. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(w):\n",
    "    return np.linalg.norm(w[:RECORD_SIZE], 2)*LAMBDA + dzeta(w).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na minimalizację powyższej funkcji nałożone są warunki:  \n",
    "<center>$y_i(w^Tx - b)\\geq 1 - \\zeta_i$ </center>  \n",
    "Co jest równoważne:  \n",
    "<center>$y_i(w^Tx - b) - 1 + \\zeta_i\\geq 0 $ </center>  \n",
    "Operacja ta w funkcji constarint jest wykonywana od razu dla całej macierzy, gdzie $\\zeta$ jest obliczane od razu jako wektor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint1(w):\n",
    "    return ((np.matmul(TRAIN_SET[:, :RECORD_SIZE], w[:RECORD_SIZE]) - w[RECORD_SIZE]) * TRAIN_SET[:, RECORD_SIZE]) + \\\n",
    "            dzeta(w) - np.ones(len(TRAIN_SET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja **dzeta** wykonuje operację:\n",
    "<center>$\\zeta_i = max(1 - f(x_i)y_i, 0)$</center>  \n",
    "dla każdego elementu macierzy z danymi i zwraca wynik jako wektor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dzeta(w):\n",
    "    return np.maximum(np.zeros(len(TRAIN_SET)), np.ones(len(TRAIN_SET)) - ((np.matmul(TRAIN_SET[:, :RECORD_SIZE], w[:RECORD_SIZE]) - w[RECORD_SIZE]) * TRAIN_SET[:, RECORD_SIZE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie SVM - program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane są ładowane do listy data, następnie tworzony jest zbiór testowy, który zostaje podzielony na 3 grupy. Uczone są 3 SVM (porównują zbiory 1 z 2, 2 z 3 i 3 z 1), które zwracają parametry *w* i *b* a ich wyniki są przekazywane do funkcji **predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Exception",
     "evalue": "Encoding error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-59b1eeb0e763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_train_test_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mset1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-2454532236de>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0msplitted_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitted_line\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitted_line\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitted_line\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6c4327e0165b>\u001b[0m in \u001b[0;36mencode\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Encoding error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: Encoding error"
     ]
    }
   ],
   "source": [
    "data = get_data()\n",
    "train_set, test_set = create_train_test_sets(0.8, data)\n",
    "set1, set2, set3 = split_data(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_12, b_12 = linear_SVM(make_4D_set(0, set1 + set2))\n",
    "w_23, b_23 = linear_SVM(make_4D_set(1, set2 + set3))\n",
    "w_31, b_31 = linear_SVM(make_4D_set(2, set3 + set1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja **predict** przyjmuje jako argument atrybuty elementu zbioru i na ich podstawie decyduje do jakiej klasy należy dany element. Robi to instrukcjami warunkowymi (jeśli widzi, że dla porównań 1 z 2 i 1 z 3 oba wskazania są na 1 to zwraca macierz odpowiadającą elementowi klasy pierwszej, analogicznie dla pozostałych zbiorów). Sytuację, w której porówniane 1 z 2 wskazuje na 2, 2 z 3 na 2 i 3 z 1 na 1 pozostawiłem nierozstrzygnięte. Porównania między dwoma klasami odbywają się za pomocą obliczenia $wx - b$ i zwrócenia 1 jeśli wynik jest większy niż 0 lub -1 jeśli mniejszy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w_12, w_23, w_31, b_12, b_23, b_31):\n",
    "    x_lpredict = [threshold_unipolar_function(np.matmul(w_12, x) - b_12, 0),\n",
    "                  threshold_unipolar_function(np.matmul(w_23, x) - b_23, 0),\n",
    "                  threshold_unipolar_function(np.matmul(w_31, x) - b_31, 0)]\n",
    "    if (x_lpredict[2] == -1) and (x_lpredict[0] == 1):\n",
    "        return [1, -1, -1]\n",
    "    if (x_lpredict[0] == -1) and (x_lpredict[1] == 1):\n",
    "        return [-1, 1, -1]\n",
    "    if (x_lpredict[1] == -1) and (x_lpredict[2] == 1):\n",
    "        return [-1, -1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja progowa unipolarna zwraca 1 jeśli *x* jest większy lub równy *a* i -1 jeśli *x* jest mniejszy od *a*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_unipolar_function(x, a):\n",
    "    if (x >= a):\n",
    "        return 1\n",
    "    elif (x < a):\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja - sprawdzenie działania algorytmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się fragment programu, który sprawdza stopień poprawnośći przewidywań przez SVM. Zbiór testowy jest podzielony na 3 klasy i dla każdej klasy przewidywana jest jej klasa na podstawie modelu. Jeśli model się pomylił dodawana jest jedynka do liczby błędów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Iris-setosa: accuracy 100.00%\n",
      "Class Iris-versicolor: accuracy 88.89%\n",
      "Class Iris-virginica: accuracy 100.00%\n",
      "Total accuracy 96.67%\n"
     ]
    }
   ],
   "source": [
    "tset1, tset2, tset3 = split_data(test_set)\n",
    "errors1 = 0\n",
    "errors2 = 0\n",
    "errors3 = 0\n",
    "\n",
    "for row in tset1:\n",
    "    if (predict(row[0], w_12, w_23, w_31, b_12, b_23, b_31) != [1, -1, -1]):\n",
    "        errors1 += 1\n",
    "print(f\"Class Iris-setosa: accuracy {(1 - errors1/len(tset1))*100:.2f}%\")\n",
    "\n",
    "for row in tset2:\n",
    "    if (predict(row[0], w_12, w_23, w_31, b_12, b_23, b_31) != [-1, 1, -1]):\n",
    "        errors2 += 1\n",
    "print(f\"Class Iris-versicolor: accuracy {(1 - errors2/len(tset2))*100:.2f}%\")\n",
    "\n",
    "for row in tset3:\n",
    "    if (predict(row[0], w_12, w_23, w_31, b_12, b_23, b_31) != [-1, -1, 1]):\n",
    "        errors3 += 1\n",
    "print(f\"Class Iris-virginica: accuracy {(1 - errors3/len(tset3))*100:.2f}%\")\n",
    "print(f\"Total accuracy {(1 - (errors1 + errors2 + errors3)/(len(tset1) + len(tset2) + len(tset3)))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trafność odpowiedzi zależy od wylosowanego zbioru treningowego i zachowania funkcji optymalizującej, ale zwykle przewyższa 90% dla całego zbioru. Przewidywanie przynależności do klasy *Iris_setosa* ma zwykle 100% trafność. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}